<?xml version="1.0"?>
<launch>
  <!-- This file launches all the vision and recognition nodes. Assumes that the cameras are running. -->

  <!-- File containing the pre-trained YOLOv5 model -->
  <arg name="weights_filename" default="/root/o2ac-ur/catkin_ws/src/o2ac_vision/config/cooking2022-08/weights/best.pt"/>

  <!-- Mode of object detector -->
  <!-- Continuous streaming is expensive and meant for debugging. -->
  <arg name="camera_name"		default="camera_multiplexer"/>
  <arg name="vis"			default="true"/>
  <arg name="use_nodelet"		default="false"/>
  <arg if="$(arg use_nodelet)"
       name="manager"			value="camera_manager"/>
  <arg unless="$(arg use_nodelet)"
       name="manager"			value=""/>

  <rosparam param="shaft_hole_detection/bbox">[375, 278, 90, 90]</rosparam>

  <!-- Construct recognition pipeline -->
  <include file="$(dirname)/recognition_pipeline_cooking.launch">
    <!-- Topic names of the camera multiplexer -->
    <arg name="camera_info_topic" value="$(arg camera_name)/camera_info"/>
    <arg name="image_topic"	  value="$(arg camera_name)/image"/>
    <arg name="depth_topic"	  value="$(arg camera_name)/depth"/>
    <arg name="normal_topic"	  value=""/>
  </include>

  <group if="$(arg vis)">
    <node name="$(anon rviz)" pkg="rviz" type="rviz" output="screen"
          args="-d $(find o2ac_vision)/launch/pipeline_test.rviz"/>
    <node name="rqt_reconfigure" pkg="rqt_reconfigure" type="rqt_reconfigure"/>
  </group>

</launch>
